{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import lightgbm as lg\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/favea/Downloads/swiss-data/train_df.csv' ,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_flights = pd.read_csv('/Users/favea/Downloads/swiss-data/previous_delayed_same_day.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(before_flights, left_on='id_flight', right_on='wh_fleg_leg_i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['departure_hour'] = train_df.scheduled_time_departure.apply(lambda x: pd.to_datetime(x).hour)\n",
    "train_df['departure_minutes'] = train_df.scheduled_time_departure.apply(lambda x: pd.to_datetime(x).minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = ['ac_subtype','wh_fleg_leg_i','id_flight','carrier','season_trip','delay_minutes','scheduled_time_departure','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = train_df.drop(columns_to_remove,axis=1)\n",
    "train_df = train_df.drop('ac_registration_code',axis=1)\n",
    "x_train, y_train = train_df.drop('delayed',axis=1), train_df.loc[:,'delayed']\n",
    "#x_train.carrier = x_train.carrier.astype('category')\n",
    "x_train.origin = x_train.origin.astype('category')\n",
    "x_train.destination = x_train.destination.astype('category')\n",
    "#x_train.previous_is_delayed = x_train.previous_is_delayed.astype('category')\n",
    "#x_train.ac_subtype = x_train.ac_subtype.astype('category')\n",
    "#x_train.ac_registration_code = x_train.ac_registration_code.astype('category')\n",
    "x_train.previous_is_delayed_same_day = x_train.previous_is_delayed_same_day.astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.previous_is_delayed_same_day = x_train.previous_is_delayed_same_day.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(x_train, y_train, categorical_feature = ['origin','destination','previous_is_delayed_same_day'], free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv('/Users/favea/Downloads/swiss-data/dev_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.merge(before_flights, left_on='id_flight', right_on='wh_fleg_leg_i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df['departure_hour'] = dev_df.scheduled_time_departure.apply(lambda x: pd.to_datetime(x).hour)\n",
    "dev_df['departure_minutes'] = dev_df.scheduled_time_departure.apply(lambda x: pd.to_datetime(x).minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.drop(columns_to_remove,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = dev_df.drop('ac_registration_code',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dev_df = dev_df.drop(columns_to_remove,axis=1)\n",
    "\n",
    "\n",
    "x_dev, y_dev = dev_df.drop('delayed',axis=1), dev_df.loc[:,'delayed']\n",
    "#x_dev.carrier = x_dev.carrier.astype('category')\n",
    "x_dev.origin = x_dev.origin.astype('category')\n",
    "x_dev.destination = x_dev.destination.astype('category')\n",
    "#x_dev.previous_is_delayed = x_dev.previous_is_delayed.astype('category')\n",
    "\n",
    "#x_dev.ac_subtype = x_dev.ac_subtype.astype('category')\n",
    "#x_dev.ac_registration_code = x_dev.ac_registration_code.astype('category')\n",
    "x_dev.previous_is_delayed_same_day = x_dev.previous_is_delayed_same_day.astype('category')\n",
    "#lgb_dev = lgb.Dataset(x_dev, y_dev, reference=lgb_train, categorical_feature =['origin','destination','previous_is_delayed_same_day'], free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_dev = lgb.Dataset(x_dev, y_dev, reference=lgb_train, categorical_feature =['origin','destination','previous_is_delayed_same_day'], free_raw_data=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Train baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train.categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_dev.categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(train_df.delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "106000/24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': ['auc','average_precision'],\n",
    "    'feature_fraction':0.8, # ration of features to randomly select\n",
    "    'bagging_fraction':0.8, # ratio of randomly selected sample of rows\n",
    "    'bagging_freq':10, # frequency of iterations to update selected rows\n",
    "    'num_leaves': 70,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'verbosity': 1,\n",
    "    'scale_pos_weight': 20,\n",
    "    'max_bin': 255,\n",
    "}\n",
    "\n",
    "wandb.init(project='swiss-delay-prediction', job_type= 'training-lightgbm-2-baseline', config=params, reinit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_dev.categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=10_000,\n",
    "                valid_sets=lgb_dev,\n",
    "                valid_names=('validation'),\n",
    "                callbacks=[wandb_callback()],\n",
    "                early_stopping_rounds=20,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_summary(gbm, save_model_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, f1_score, precision_recall_fscore_support, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = gbm.predict(x_dev, num_iteration=gbm.best_iteration)\n",
    "\n",
    "roc_ac = roc_auc_score(y_dev, y_pred)\n",
    "wandb.log({'val_roc_auc': roc_ac})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_confusion_matrix(y_dev, (y_pred>=0.5).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = gbm.predict(x_train, num_iteration=gbm.best_iteration)\n",
    "print(classification_report(y_train, (y_train_pred>=0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = classification_report(y_dev, (y_pred>=0.5).astype(int), output_dict=True)\n",
    "sensitivity = d['1']['recall']\n",
    "specificity = d['0']['recall']\n",
    "f1_score = d['macro avg']['f1-score']\n",
    "\n",
    "wandb.summary['sensitivity'] = sensitivity\n",
    "wandb.summary['specificity'] = specificity\n",
    "wandb.summary['f1_score'] = f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_dev, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay.from_predictions(    \n",
    "    y_dev,\n",
    "    y_pred,\n",
    "    color=\"darkorange\",\n",
    "    name = 'LightGBM'\n",
    ")\n",
    "plt.plot()\n",
    "wandb.log({'PR-curve':wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(\n",
    "    y_dev,\n",
    "    y_pred,\n",
    "    color=\"darkorange\",\n",
    ")\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "\n",
    "wandb.log({'ROC-curve':wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For heavily unbalanced datasets such as 1:10000:\n",
    "\n",
    "max_bin: keep it only for memory pressure, not to tune (otherwise overfitting)\n",
    "\n",
    "learning rate: keep it only for training speed, not to tune (otherwise overfitting)\n",
    "\n",
    "n_estimators: must be infinite (like 9999999) and use early stopping to auto-tune (otherwise overfitting)\n",
    "\n",
    "num_leaves: [7, 4095]\n",
    "\n",
    "max_depth: [2, 63] and infinite (I personally saw metric performance increases with such 63 depth with small number of leaves on sparse unbalanced datasets)\n",
    "\n",
    "scale_pos_weight: [1, 10000] (if over 10000, something might be wrong because I never saw it that good after 5000)\n",
    "\n",
    "min_child_weight: [0.01, (sample size / 1000)] if you are using logloss (think about the hessian possible value rang\n",
    "e before putting \"sample size / 1000\", it is dataset-dependent and loss-dependent)\n",
    "\n",
    "\n",
    "subsample: [0.4, 1]\n",
    "\n",
    "\n",
    "bagging_freq: only 1, keep as is (otherwise overfitting)\n",
    "\n",
    "colsample_bytree: [0.4, 1]\n",
    "\n",
    "is_unbalance: false (make your own weighting with scale_pos_weight)\n",
    "\n",
    "USE A CUSTOM METRIC (to reflect reality without weighting, otherwise you have weights inside your metric with premade metrics like xgboost)\n",
    "\n",
    "Never tune these parameters unless you have an explicit requirement to tune them:\n",
    "\n",
    "Learning rate (lower means longer to train but more accurate, higher means smaller to train but less accurate)\n",
    "\n",
    "Number of boosting iterations (automatically tuned with early stopping and learning rate)\n",
    "\n",
    "Maximum number of bins (RAM dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': ['auc','average_precision'],\n",
    "    'feature_fraction':0.8, # ration of features to randomly select\n",
    "    'bagging_fraction':0.8, # ratio of randomly selected sample of rows\n",
    "    'bagging_freq':10, # frequency of iterations to update selected rows\n",
    "    'num_leaves': 70,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.02,\n",
    "    'verbosity': 1,\n",
    "    'scale_pos_weight': 20,\n",
    "    'max_bin': 255,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "  \"method\" : \"bayes\",\n",
    "  \"metric\": {\n",
    "      \"name\": \"avg_precision_dev\",\n",
    "      \"goal\": \"maximize\"\n",
    "  },\n",
    "  \"parameters\" : {\n",
    "    \"gamma\" :{\n",
    "      \"min\": 0.001,\n",
    "      \"max\": 1.0\n",
    "    },\n",
    "    \"min_child_weight\" :{\n",
    "      \"min\": 1,\n",
    "      \"max\": 150\n",
    "    },\n",
    "    \"scale_pos_weight\":{\n",
    "      \"min\": 1,\n",
    "      \"max\": 30,\n",
    "    },\n",
    "    \"num_leaves\" :{\n",
    "      \"min\": 10,\n",
    "      \"max\": 100\n",
    "    },\n",
    "    \"max_depth\" :{\n",
    "      \"min\": 5,\n",
    "      \"max\": 40\n",
    "    },\n",
    "    \"feature_fraction\" :{\n",
    "      \"min\": 0.3,\n",
    "      \"max\": 1.0\n",
    "    },\n",
    "    \"bagging_fraction\" :{\n",
    "      \"min\": 0.3,\n",
    "      \"max\": 1.0\n",
    "    },\n",
    "\n",
    "    \"lambda_l1\":{\"values\":[0.5, 0.8, 1]},\n",
    "    \"lambda_l2\":{\"values\":[0.5, 0.8, 1]},\n",
    "    \n",
    "\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():     \n",
    "    with wandb.init() as run:\n",
    "\n",
    "        params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'metric': ['auc','average_precision'],\n",
    "            'objective': 'binary',\n",
    "            'num_leaves': run.config['num_leaves'],\n",
    "            'learning_rate': 0.008,\n",
    "            'bagging_freq': 10,\n",
    "            'verbosity': 1,\n",
    "            'scale_pos_weight': run.config['scale_pos_weight'],\n",
    "            'bagging_fraction': run.config['bagging_fraction'],\n",
    "            'max_depth': run.config['max_depth'],\n",
    "            'scale_pos_weight': run.config['scale_pos_weight'],\n",
    "            'feature_fraction': run.config['feature_fraction'],\n",
    "            'lambda_l2':run.config['lambda_l2'],\n",
    "            'lambda_l1':run.config['lambda_l1'],\n",
    "            'max_bin':255,\n",
    "\n",
    "        }\n",
    "    \n",
    "\n",
    "        # Initialize and train LightGBM model\n",
    "        gbm = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=10000, #infinite\n",
    "                        valid_sets=lgb_dev,\n",
    "                        valid_names=('validation'),\n",
    "                        callbacks=[wandb_callback()],\n",
    "                        early_stopping_rounds=20,\n",
    "                        )\n",
    "\n",
    "        log_summary(gbm, save_model_checkpoint=True)\n",
    "        \n",
    "\n",
    "\n",
    "        # Log booster metrics\n",
    "        run.summary[\"best_score\"] = gbm.best_score\n",
    "        run.summary[\"best_iteration\"] = gbm.best_iteration\n",
    "        \n",
    "        # Get train and validation predictions\n",
    "        y_dev_pred = gbm.predict(x_dev, num_iteration=gbm.best_iteration)\n",
    "        y_train_pred = gbm.predict(x_train, num_iteration=gbm.best_iteration)\n",
    "\n",
    "\n",
    "        # Log additional Train metrics\n",
    "        false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_train, y_train_pred) \n",
    "\n",
    "        avg_precision_train = average_precision_score(y_train, y_train_pred)\n",
    "        run.summary['train_avg_precision'] = avg_precision_train\n",
    "        run.summary['train_auc'] = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "        run.summary['train_log_loss'] = -(y_train * np.log(y_train_pred) + (1-y_train) * np.log(1-y_train_pred)).sum() / len(y_train)\n",
    "\n",
    "        # Log additional Validation metrics\n",
    "        avg_precision_dev = average_precision_score(y_dev, y_dev_pred)\n",
    "        run.summary['avg_precision_dev'] = avg_precision_dev\n",
    "        run.summary[\"val_auc\"] = metrics.roc_auc_score(y_dev, y_dev_pred)\n",
    "        run.summary[\"val_acc_0.5\"] = metrics.accuracy_score(y_dev, np.where(y_dev_pred >= 0.5, 1, 0))\n",
    "        run.summary[\"val_log_loss\"] = -(y_dev * np.log(y_dev_pred) \n",
    "                                             + (1-y_dev) * np.log(1-y_dev_pred)).sum() / len(y_dev)\n",
    "\n",
    "        d = classification_report(y_dev, np.where(y_dev_pred >= 0.5, 1, 0), output_dict=True)\n",
    "        sensitivity = d['1']['recall']\n",
    "        specificity = d['0']['recall']\n",
    "        f1_score = d['macro avg']['f1-score']\n",
    "\n",
    "        run.summary['val_sensitivity_0.5'] = sensitivity\n",
    "        run.summary['val_specificity_0.5'] = specificity\n",
    "        run.summary['val_f1_score'] = f1_score\n",
    "\n",
    "\n",
    "        # Log plots\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_dev,\n",
    "            y_dev_pred,\n",
    "            color=\"darkorange\",\n",
    "        )\n",
    "        plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "        plt.axis(\"square\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.legend()\n",
    "        run.log({'ROC-curve-dev':wandb.Image(plt)})\n",
    "\n",
    "        display = PrecisionRecallDisplay.from_predictions(    \n",
    "            y_dev,\n",
    "            y_dev_pred,\n",
    "            color=\"darkorange\",\n",
    "            name = 'LightGBM'\n",
    "        )\n",
    "        plt.plot()\n",
    "        plt.xlabel(\"Precision\")\n",
    "        plt.ylabel(\"Recall\")\n",
    "        plt.legend()\n",
    "        run.log({'PR-curve-dev':wandb.Image(plt)})\n",
    "        try:\n",
    "            wandb.sklearn.plot_confusion_matrix(y_dev, (y_dev_pred>=0.5).astype(int))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        #run.log({'feature_importance':fig})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"swiss-delay-prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000 # number of runs to execute\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('swiss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27173ca9e262779112d37ff834a183edc1f32234e7a598e599b2cfd0e10e4ba1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
